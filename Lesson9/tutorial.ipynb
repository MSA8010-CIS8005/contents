{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Your Data\n",
    "\n",
    "The majority of a data scientist's time is actually spent preparing data because the data is seldom in any order to actually perform analysis. To prepare data for use, a data scientist must: <br /><br />\n",
    "Get the data<br />\n",
    "Aggregate the data<br />\n",
    "Create data subsets<br />\n",
    "Clean the data<br />\n",
    "Develop a single dataset by merging various datasets together<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figuring out whatâ€™s in your data\n",
    "\n",
    "Finding duplicates is important because you end up <br /><br />\n",
    "Spending more computational time to process duplicates.<br />\n",
    "Obtaining false results because duplicates implicitly overweight the results.<br /><br />\n",
    "An example of how to find duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lxml import objectify\n",
    "import pandas as pd\n",
    "\n",
    "xml = objectify.parse(open('XMLData2.xml'))\n",
    "root = xml.getroot()\n",
    "df = pd.DataFrame(columns=('Number', 'String', 'Boolean'))\n",
    "\n",
    "for i in range(0,8):\n",
    "    obj = root.getchildren()[i].getchildren()\n",
    "    # zip as discussed before makes a tuple of combination of two lists such as [('Number', '1'), ('String', 'First'), ('Boolean', 'True')]\n",
    "    row = dict(zip(['Number', 'String', 'Boolean'], \n",
    "                   [obj[0].text, obj[1].text, \n",
    "                    obj[2].text]))\n",
    "    \n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = i\n",
    "    df = df.append(row_s)\n",
    "    \n",
    "# gives you a Series values False or if duplicate True    \n",
    "search = pd.DataFrame.duplicated(df)\n",
    "\n",
    "print df\n",
    "print\n",
    "print search\n",
    "print search[search == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lxml import objectify\n",
    "import pandas as pd\n",
    "\n",
    "xml = objectify.parse(open('XMLData2.xml'))\n",
    "root = xml.getroot()\n",
    "df = pd.DataFrame(columns=('Number', 'String', 'Boolean'))\n",
    "\n",
    "for i in range(0,8):\n",
    "    obj = root.getchildren()[i].getchildren()\n",
    "    row = dict(zip(['Number', 'String', 'Boolean'], \n",
    "                   [obj[0].text, obj[1].text, \n",
    "                    obj[2].text]))\n",
    "    row_s = pd.Series(row)\n",
    "    row_s.name = i\n",
    "    df = df.append(row_s)\n",
    "    \n",
    "print df\n",
    "print df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating categorical variables\n",
    "\n",
    "Categorical variables have a specific number of values, which makes them incredibly valuable in performing a number of data science tasks. For example, imagine trying to find values that are out of range in a huge dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print pd.version.version\n",
    "\n",
    "car_colors = pd.Series(['Blue', 'Red', 'Green'], dtype='category')\n",
    "\n",
    "car_data = pd.Series(\n",
    "    pd.Categorical(['Yellow', 'Green', 'Red', 'Blue', 'Purple'],\n",
    "                   categories=list(car_colors), ordered=False))\n",
    "\n",
    "find_entries = pd.isnull(car_data)\n",
    "\n",
    "print car_colors\n",
    "print\n",
    "print car_data\n",
    "print\n",
    "print find_entries[find_entries == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming levels\n",
    "\n",
    "There are sometimes when the naming of the categories you use is inconvenient or otherwise wrong for a particular need. You can rename the categories as needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "car_colors = pd.Series(['Blue', 'Red', 'Green'], \n",
    "                       dtype='category')\n",
    "car_data = pd.Series(\n",
    "    pd.Categorical(\n",
    "        ['Blue', 'Green', 'Red', 'Blue', 'Red'],\n",
    "        categories=list(car_colors), ordered=False))\n",
    "\n",
    "\n",
    "car_colors.cat.categories = [\"Purple\", \"Yellow\", \"Mauve\"]\n",
    "car_data.cat.categories = list(car_colors)\n",
    "\n",
    "print car_colors\n",
    "print car_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining levels\n",
    "\n",
    "A particular categorical level might be too small to offer significant data for analysis. Perhaps there are only a few of the values. In this case, combining several small categories might offer better analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "car_colors = pd.Series(['Blue', 'Red', 'Green'], \n",
    "                       dtype='category')\n",
    "car_data = pd.Series(\n",
    "    pd.Categorical(\n",
    "        ['Blue', 'Green', 'Red', 'Green', 'Red', 'Green'],\n",
    "        categories=car_colors, ordered=False))\n",
    "\n",
    "car_data.cat.categories = [\"Blue_Red\", \"Red\", \"Green\"]\n",
    "\n",
    "\n",
    "car_data.ix[car_data.isin(['Red'])] = 'Blue_Red'\n",
    "\n",
    "print\n",
    "print car_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Dates in Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting time values\n",
    "\n",
    "Obtaining the correct date and time representation can make performing analysis a lot easier. For example, you often have to change the representation to obtain a correct sorting of values. Python provides two common methods of formatting date and time. The first technique is to call str(), which simply turns a datetime value into a string without formatting. The strftime() function requires more work because you must define how you want the datetime value to appear after conversion. When using strftime(), you must provide a string containing special directives that define the formatting. You can find a listing of these directives at http://strftime.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "now = dt.datetime.now()\n",
    "\n",
    "print str(now)\n",
    "print now.strftime('%a, %d %B %Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the right time transformation\n",
    "\n",
    "Time zones differences in local time can cause all sorts of problems when performing analysis. For that matter, some types of calculations simply require a time shift in order to get the right results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "now = dt.datetime.now()\n",
    "timevalue = now + dt.timedelta(hours=2)\n",
    "\n",
    "print now.strftime('%H:%M:%S')\n",
    "print timevalue.strftime('%H:%M:%S')\n",
    "print timevalue - now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding out missing data\n",
    "\n",
    "It's essential to find missing data in your dataset to avoid getting incorrect results from your analysis. The following code shows how you can obtain a listing of missing values without too much effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s = pd.Series([1, 2, 3, np.NaN, 5, 6, None])\n",
    "\n",
    "print s.isnull()\n",
    "\n",
    "print\n",
    "print s[s.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding missingness\n",
    "\n",
    "After you figure out that dataset is missing information, you need to consider what to do about it. The three possibilities are to ignore the issue, fill in the missing items, or remove (drop) the missing entries from the dataset. Ignoring the problem could lead to all sorts of problems so in most cases it is not the right approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s = pd.Series([1, 2, 3, np.NaN, 5, 6, None])\n",
    "\n",
    "print s.fillna(int(s.mean()))\n",
    "print\n",
    "print s.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing and Dicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array([[[1, 2, 3],  [4, 5, 6],  [7, 8, 9]],\n",
    "              [[11,12,13], [14,15,16], [17,18,19]],\n",
    "              [[21,22,23], [24,25,26], [27,28,29]]])\n",
    "\n",
    "x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array([[[1, 2, 3],  [4, 5, 6],  [7, 8, 9],],\n",
    "              [[11,12,13], [14,15,16], [17,18,19],],\n",
    "              [[21,22,23], [24,25,26], [27,28,29]]])\n",
    "\n",
    "x[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array([[[1, 2, 3],  [4, 5, 6],  [7, 8, 9],],\n",
    "              [[11,12,13], [14,15,16], [17,18,19],],\n",
    "              [[21,22,23], [24,25,26], [27,28,29]]])\n",
    "\n",
    "print x[1,1]\n",
    "print\n",
    "print x[:,1,1]\n",
    "print\n",
    "print x[1,:,1]\n",
    "print\n",
    "print x[1:3, 1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating and Transforming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new cases and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [2,3,1],\n",
    "                   'B': [1,2,3],\n",
    "                   'C': [5,3,4]})\n",
    "\n",
    "print df\n",
    "print\n",
    "\n",
    "df1 = pd.DataFrame({'A': [4],\n",
    "                    'B': [4],\n",
    "                    'C': [4]})\n",
    "\n",
    "print df1\n",
    "print\n",
    "\n",
    "df = df.append(df1)\n",
    "\n",
    "print df\n",
    "print\n",
    "\n",
    "# resets the index, drop=True means dont add any index column\n",
    "df = df.reset_index(drop=True)\n",
    "print df\n",
    "\n",
    "df.loc[df.last_valid_index() + 1] = [5, 5, 5]\n",
    "print\n",
    "print df\n",
    "\n",
    "df2 = pd.DataFrame({'D': [1, 2, 3, 4, 5]})\n",
    "\n",
    "df = pd.DataFrame.join(df, df2)\n",
    "print\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [2,3,1],\n",
    "                   'B': [1,2,3],\n",
    "                   'C': [5,3,4]})\n",
    "\n",
    "print df\n",
    "print\n",
    "\n",
    "df = df.drop(df.index[[1]])\n",
    "print df\n",
    "\n",
    "# drop B on axis = 1 (columns)\n",
    "df = df.drop('B', 1)\n",
    "print\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting and shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'A': [2,1,2,3,3,5,4],\n",
    "                   'B': [1,2,3,5,4,2,5],\n",
    "                   'C': [5,3,4,1,1,2,3]})\n",
    "\n",
    "df = df.sort_index(by=['A', 'B'], ascending=[True, True])\n",
    "print df\n",
    "print\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "print df\n",
    "print\n",
    "\n",
    "index = df.index.tolist()\n",
    "np.random.shuffle(index)\n",
    "df = df.ix[index]\n",
    "print df\n",
    "print\n",
    "df = df.reset_index(drop=True)\n",
    "print\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating Data at Any Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Map': [0,0,0,1,1,2,2],\n",
    "                   'Values': [1,2,3,5,4,2,5]})\n",
    "\n",
    "print df\n",
    "print\n",
    "\n",
    "\n",
    "df['S'] = df.groupby('Map')['Values'].transform(np.sum)\n",
    "df['M'] = df.groupby('Map')['Values'].transform(np.mean)\n",
    "df['V'] = df.groupby('Map')['Values'].transform(np.var)\n",
    "\n",
    "print df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
